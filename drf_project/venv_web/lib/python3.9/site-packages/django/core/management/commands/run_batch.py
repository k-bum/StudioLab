from django.core.management.base import BaseCommand
import asyncio
import subprocess
from crawler.models import Project, Crawler
from asgiref.sync import sync_to_async
from datetime import timedelta, datetime
import time
import psutil

class Command(BaseCommand):
    help = 'Run the batch program'
    def check_processes(self):
            #processes = subprocess.run(['ps', 'aux'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            #process_list = processes.stdout.decode().split("\n")
            #pid_list=[]
            #try:
            #    for process in process_list:
            #        pid=process[1]
            #        pid_list.append(pid)
            #except:
                #print("No process yet")
            #    pid_list=[]
            #return pid_list

            pids = [p.pid for p in psutil.process_iter()]
            return pids

    def update_state(self):
            projects=Project.objects.all()
            #crawlers=Crawler.objects.all()
            
            #projects = sync_to_async(Project.objects.all)()
            process_list=self.check_processes()
            start_time = time.time()
            print(start_time)
            #print("Current process: ", process_list)
            for project in projects:
                print(f"Project [{project.title}](id: {project.id}, state: {project.state})")
                project_id=project.id
                
                crawlers_in_project = Crawler.objects.filter(project=project_id)
                crawler_pids = list(crawlers_in_project.values_list('pid', flat=True))
                print(f"Crawler pid : {crawler_pids}")
                not_running_count=0
                proj_finished=False

                # crawler 중 하나라도 running 이면 Project의 state는 running
                for c in crawlers_in_project: # c: record 객체
                    print(f"  - Crawler {str(c.id)} in Project {str(project.id)} (pid: {str(c.pid)}): {c.state}")
                    
                    if c.state=="Running": # Check if there's abnormal termination of process
                        if c.pid not in process_list:
                            c.state="Stopped" # Process was terminated abnormally
                            c.remaining=timedelta(hours=0, minutes=0, seconds=0)
                            c.save()
                    
                    if c.state=="Running": # update remaining time for running crawlers
                        try:
                            new_remaining = (c.expected_total-c.collected) * (c.elapsed/c.collected)
                            c.remaining=new_remaining
                            c.save()
                        except:
                            pass            
                    
                    c_finished = 0 if c.state == "Running" else 1
                    not_running_count+=c_finished
                
                if (len(crawlers_in_project)!=0) and (not_running_count==len(crawlers_in_project)):
                    proj_finished = True

                if (len(crawlers_in_project)!=0) and (not_running_count!=len(crawlers_in_project)):
                    project.state = "Running"
                
                # 프로젝트 남은시간 update    
                if proj_finished:
                    project.state="Done"
                    project.remaining=timedelta(hours=0, minutes=0, seconds=0)
                    project.save()
                    
                else:
                    if(len(crawlers_in_project) != 0) :
                        remaining=crawlers_in_project[0].remaining
                        for c in crawlers_in_project:
                            remaining = max(remaining, c.remaining)
                        project.remaining=remaining 
                        project.save()

                print(f"Project [{str(project.title)}] ({str(project.id)}) : {not_running_count}/{len(crawlers_in_project)} finished\n\n")
    
    def run(self):
        print("Batch program start")

        while True:
            self.update_state()
            crawlers=Crawler.objects.filter(state="Running")
            projects=Project.objects.filter(state="Running")
            end_datetime = datetime.now()
            for crawler in crawlers:
                elapsed = end_datetime - crawler.create_dt
                elapsed_timedelta = timedelta(seconds=elapsed.total_seconds())
                crawler.elapsed = elapsed_timedelta
                crawler.save()
            for project in projects:
                elapsed = end_datetime - project.create_dt
                elapsed_timedelta = timedelta(seconds=elapsed.total_seconds())
                project.elapsed = elapsed_timedelta
                project.save()
            time.sleep(5)
              
    def handle(self, *args, **options):
        self.run()
